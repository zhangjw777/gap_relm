#!/bin/bash
# Gap-ReLM DDP å¤šå¡è®­ç»ƒå¯åŠ¨è„šæœ¬
# ç”¨äºPlanner + Infillerè”åˆå¤šä»»åŠ¡è®­ç»ƒ

# ========== å¿…å¡«å‚æ•° ==========
TRAIN_FILE="./static_training_data/train.jsonl"  # é¢„ç”Ÿæˆçš„é™æ€è®­ç»ƒæ•°æ®ï¼ˆå¸¦é¢„è®¡ç®—æ ‡ç­¾ï¼‰
DEV_FILE="./static_training_data/dev.jsonl"      # é¢„ç”Ÿæˆçš„é™æ€éªŒè¯æ•°æ®

# ========== åŸºç¡€é…ç½® ==========
OUTPUT_DIR="./outputs"                     # è¾“å‡ºç›®å½•
EXPERIMENT_NAME="gap_relm_joint_training"  # å®éªŒåç§°
NUM_GPUS=2                                 # GPUæ•°é‡ï¼ˆæ ¹æ®å®é™…æƒ…å†µä¿®æ”¹ï¼‰
DATA_FORMAT="mucgec"                       # æ•°æ®æ ¼å¼ï¼ˆmucgec/sighan/ecspell/custom/parallelï¼‰

# ========== è®­ç»ƒç­–ç•¥ ==========
TRAINING_STAGE="joint_finetune"            # è®­ç»ƒé˜¶æ®µï¼ˆjoint_finetune=è”åˆè®­ç»ƒï¼‰
NUM_EPOCHS=10                              # è®­ç»ƒè½®æ•°
BATCH_SIZE=64                              # æ¯ä¸ªGPUçš„batch size
GRADIENT_ACCUMULATION_STEPS=2              # æ¢¯åº¦ç´¯ç§¯æ­¥æ•°

# ========== ä¼˜åŒ–å™¨å‚æ•° ==========
LEARNING_RATE=2e-5                         # å­¦ä¹ ç‡
WARMUP_RATIO=0.1                           # é¢„çƒ­æ¯”ä¾‹
WEIGHT_DECAY=0.01                          # æƒé‡è¡°å‡
MAX_GRAD_NORM=1.0                          # æ¢¯åº¦è£å‰ª

# ========== æ¨¡å‹å‚æ•° ==========
PRETRAINED_MODEL="hfl/chinese-macbert-base"  # é¢„è®­ç»ƒæ¨¡å‹
MAX_SEQ_LENGTH=128                         # æœ€å¤§åºåˆ—é•¿åº¦
MAX_INSERT_NUM=3                           # æœ€å¤§æ’å…¥æ•°é‡K

# ========== æ··åˆç²¾åº¦è®­ç»ƒ ==========
USE_FP16=true                              # ä½¿ç”¨FP16æ··åˆç²¾åº¦ï¼ˆæ¨èï¼‰
USE_BF16=false                             # ä½¿ç”¨BF16æ··åˆç²¾åº¦ï¼ˆå¦‚æœGPUæ”¯æŒï¼‰

# ========== æ•°æ®åŠ è½½ ==========
NUM_WORKERS=4                              # æ•°æ®åŠ è½½è¿›ç¨‹æ•°ï¼ˆå»ºè®® 4-16ï¼Œåœ¨çº¿å¢å¼ºæ—¶å¢å¤§ï¼‰
PREFETCH_FACTOR=4                          # æ¯ä¸ªworkeré¢„å–çš„batchæ•°ï¼ˆé»˜è®¤2ï¼Œå¯å¢å¤§åˆ°4-8ï¼‰
CACHE_DIR="./cache"                        # ç¼“å­˜ç›®å½•
USE_CACHE=true                             # æ˜¯å¦ä½¿ç”¨ç¼“å­˜
LAZY_LOAD=true                            # æƒ°æ€§åŠ è½½æ¨¡å¼ï¼ˆæ¨èå¤§æ•°æ®é›†>100ä¸‡æ ·æœ¬ä½¿ç”¨ï¼ŒèŠ‚çœå†…å­˜ï¼‰

# ========== é¢„è®¡ç®— tokenize æ•°æ®ï¼ˆæœ€é«˜æ•ˆæ¨¡å¼ï¼‰ ==========
# å¦‚æœä½¿ç”¨é¢„è®¡ç®—çš„äºŒè¿›åˆ¶æ•°æ®ï¼Œè®¾ç½® USE_TOKENIZED_DATA=true
# å¹¶æŒ‡å®šæ•°æ®æ–‡ä»¶å‰ç¼€ï¼ˆä¸å« .bin/.idx åç¼€ï¼‰
USE_TOKENIZED_DATA=true                   # æ˜¯å¦ä½¿ç”¨é¢„è®¡ç®— tokenize æ•°æ®
TRAIN_DATA_PREFIX="./tokenized_data/train"                       # è®­ç»ƒæ•°æ®å‰ç¼€ï¼Œå¦‚ ./tokenized_data/train
DEV_DATA_PREFIX="./tokenized_data/dev"                         # éªŒè¯æ•°æ®å‰ç¼€ï¼Œå¦‚ ./tokenized_data/dev
TEST_DATA_PREFIX="./tokenized_data/test"                        # æµ‹è¯•æ•°æ®å‰ç¼€ï¼ˆå¯é€‰ï¼‰

# ========== åœ¨çº¿åŠ¨æ€æ•°æ®å¢å¼º ==========
# æ³¨æ„ï¼šä½¿ç”¨é¢„ç”Ÿæˆé™æ€æ•°æ®æ—¶ï¼Œè®¾ç½® ONLINE_AUGMENT=false
ONLINE_AUGMENT=false                       # å…³é—­åœ¨çº¿åŠ¨æ€æ•°æ®å¢å¼ºï¼ˆä½¿ç”¨é¢„ç”Ÿæˆé™æ€æ•°æ®ï¼‰
CLEAN_TRAIN_FILE=""                        # å¹²å‡€è®­ç»ƒå¥å­æ–‡ä»¶ï¼ˆç•™ç©ºï¼šä½¿ç”¨é¢„ç”Ÿæˆæ•°æ®ï¼‰
FROZEN_DEV_FILE=""                         # å›ºå®šéªŒè¯é›†æ–‡ä»¶ï¼ˆç•™ç©ºï¼šä½¿ç”¨DEV_FILEï¼‰
CLEAN_FILE_FORMAT="txt"                    # å¹²å‡€æ–‡ä»¶æ ¼å¼ï¼ˆtxt/json/jsonlï¼‰
P_CORRUPT=0.7                              # é€ é”™æ¦‚ç‡
BASE_LAMBDA=1.5                            # åŸºç¡€æ³Šæ¾å‚æ•°
PI_SKIP=0.2                                # åˆ å­—æ¦‚ç‡
PI_MULTIPLY=0.3                            # é‡å¤å­—æ¦‚ç‡
PI_REPLACE=0.5                             # é”™å­—æ¦‚ç‡

# é•¿åº¦è‡ªé€‚åº” Î»
ENABLE_LENGTH_ADAPTIVE=true                # å¯ç”¨é•¿åº¦è‡ªé€‚åº”Î»
MIN_LENGTH_FOR_LAMBDA=20                   # Î»æœ€å°å€¼å¯¹åº”çš„å¥å­é•¿åº¦
MAX_LENGTH_FOR_LAMBDA=80                   # Î»æœ€å¤§å€¼å¯¹åº”çš„å¥å­é•¿åº¦
MIN_LAMBDA=1.0                             # æœ€å°Î»å€¼
MAX_LAMBDA=3.0                             # æœ€å¤§Î»å€¼

# ========== æ¶ˆèå®éªŒå¼€å…³ ==========
ENABLE_INSERT=true                         # å¯ç”¨æ’å…¥æ“ä½œ
ENABLE_DELETE=true                         # å¯ç”¨åˆ é™¤æ“ä½œ
ENABLE_AUX_MLM=true                        # å¯ç”¨è¾…åŠ©MLMä»»åŠ¡

# ========== MASK æ¨¡å¼ ==========
# Full MASK æ¨¡å¼ï¼ˆReLM é£æ ¼ï¼‰ï¼šæ¨¡æ¿æ ¼å¼ä¸º [CLS] source [SEP] [MASK]*N [SEP]
# ç¨€ç– MASK æ¨¡å¼ï¼šåªåœ¨ç¼–è¾‘ä½ç½®æ”¾ç½® [MASK]
FULL_MASK_MODE=true                        # true=Full MASKæ¨¡å¼ï¼ˆé»˜è®¤ï¼‰ï¼Œfalse=ç¨€ç–MASKæ¨¡å¼

# ========== P-Tuning é…ç½® ==========
ENABLE_PTUNING=true                        # å¯ç”¨P-Tuningï¼ˆé»˜è®¤å¼€å¯ï¼‰
PTUNING_PROMPT_LENGTH=10                   # Prompté•¿åº¦
PTUNING_USE_LSTM=true                      # ä½¿ç”¨LSTMç¼–ç prompt
PTUNING_SHARED=false                       # Planner/Infillerå…±äº«promptï¼ˆfalse=å„è‡ªç‹¬ç«‹ï¼‰

# ========== F2ä¼˜åŒ– ==========
ENABLE_F2=true                             # å¯ç”¨F2ä¼˜åŒ–
DELETE_THRESHOLD=0.3                       # åˆ é™¤é˜ˆå€¼
INSERT_THRESHOLD=0.3                       # æ’å…¥é˜ˆå€¼

# ========== æ—¥å¿—å’Œä¿å­˜ ==========
LOGGING_STEPS=100                          # æ—¥å¿—è¾“å‡ºæ­¥æ•°
SAVE_STEPS=500                             # ä¿å­˜æ£€æŸ¥ç‚¹æ­¥æ•°
EVAL_STEPS=500                             # è¯„ä¼°æ­¥æ•°

# ========== å…¶ä»– ==========
SEED=42                                    # éšæœºç§å­

# ========== è§£æå‘½ä»¤è¡Œå‚æ•°ï¼ˆè¦†ç›–é»˜è®¤å€¼ï¼‰==========
while [[ $# -gt 0 ]]; do
    case $1 in
        --train_file)
            TRAIN_FILE="$2"
            shift 2
            ;;
        --dev_file)
            DEV_FILE="$2"
            shift 2
            ;;
        --output_dir)
            OUTPUT_DIR="$2"
            shift 2
            ;;
        --experiment_name)
            EXPERIMENT_NAME="$2"
            shift 2
            ;;
        --num_gpus)
            NUM_GPUS="$2"
            shift 2
            ;;
        --batch_size)
            BATCH_SIZE="$2"
            shift 2
            ;;
        --num_epochs)
            NUM_EPOCHS="$2"
            shift 2
            ;;
        --learning_rate)
            LEARNING_RATE="$2"
            shift 2
            ;;
        --data_format)
            DATA_FORMAT="$2"
            shift 2
            ;;
        --training_stage)
            TRAINING_STAGE="$2"
            shift 2
            ;;
        --no_ptuning)
            ENABLE_PTUNING=false
            shift
            ;;
        --ptuning_prompt_length)
            PTUNING_PROMPT_LENGTH="$2"
            shift 2
            ;;
        --ptuning_no_lstm)
            PTUNING_USE_LSTM=false
            shift
            ;;
        --ptuning_shared)
            PTUNING_SHARED=true
            shift
            ;;
        # åœ¨çº¿åŠ¨æ€æ•°æ®å¢å¼ºå‚æ•°
        --online_augment)
            ONLINE_AUGMENT=true
            shift
            ;;
        --no_online_augment)
            ONLINE_AUGMENT=false
            shift
            ;;
        --clean_train_file)
            CLEAN_TRAIN_FILE="$2"
            shift 2
            ;;
        --frozen_dev_file)
            FROZEN_DEV_FILE="$2"
            shift 2
            ;;
        --clean_file_format)
            CLEAN_FILE_FORMAT="$2"
            shift 2
            ;;
        --p_corrupt)
            P_CORRUPT="$2"
            shift 2
            ;;
        --base_lambda)
            BASE_LAMBDA="$2"
            shift 2
            ;;
        --pi_skip)
            PI_SKIP="$2"
            shift 2
            ;;
        --pi_multiply)
            PI_MULTIPLY="$2"
            shift 2
            ;;
        --pi_replace)
            PI_REPLACE="$2"
            shift 2
            ;;
        --no_length_adaptive)
            ENABLE_LENGTH_ADAPTIVE=false
            shift
            ;;
        --min_lambda)
            MIN_LAMBDA="$2"
            shift 2
            ;;
        --max_lambda)
            MAX_LAMBDA="$2"
            shift 2
            ;;
        --lazy_load)
            LAZY_LOAD=true
            shift
            ;;
        --full_mask_mode)
            FULL_MASK_MODE=true
            shift
            ;;
        --sparse_mask_mode)
            FULL_MASK_MODE=false
            shift
            ;;
        --tokenized_data)
            USE_TOKENIZED_DATA=true
            shift
            ;;
        --train_data_prefix)
            TRAIN_DATA_PREFIX="$2"
            shift 2
            ;;
        --dev_data_prefix)
            DEV_DATA_PREFIX="$2"
            shift 2
            ;;
        --test_data_prefix)
            TEST_DATA_PREFIX="$2"
            shift 2
            ;;
        *)
            echo "Unknown option: $1"
            echo "Available options:"
            echo "  --train_file <path>          è®­ç»ƒæ•°æ®æ–‡ä»¶ï¼ˆå¿…å¡«ï¼‰"
            echo "  --dev_file <path>            éªŒè¯æ•°æ®æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰"
            echo "  --output_dir <path>          è¾“å‡ºç›®å½•"
            echo "  --experiment_name <name>     å®éªŒåç§°"
            echo "  --num_gpus <N>               GPUæ•°é‡"
            echo "  --batch_size <N>             batch size"
            echo "  --num_epochs <N>             è®­ç»ƒè½®æ•°"
            echo "  --learning_rate <float>      å­¦ä¹ ç‡"
            echo "  --data_format <format>       æ•°æ®æ ¼å¼ï¼ˆmucgec/sighan/...ï¼‰"
            echo "  --training_stage <stage>     è®­ç»ƒé˜¶æ®µï¼ˆjoint_finetune/infiller_pretrain/planner_trainï¼‰"
            echo "  --no_ptuning                 å…³é—­P-Tuningï¼ˆæ¶ˆèå®éªŒï¼‰"
            echo "  --ptuning_prompt_length <N>  P-Tuning prompté•¿åº¦"
            echo "  --ptuning_no_lstm            P-Tuningä¸ä½¿ç”¨LSTM"
            echo "  --ptuning_shared             P-Tuningä½¿ç”¨å…±äº«prompt"
            echo ""
            echo "åœ¨çº¿åŠ¨æ€æ•°æ®å¢å¼ºé€‰é¡¹:"
            echo "  --online_augment             å¯ç”¨åœ¨çº¿åŠ¨æ€æ•°æ®å¢å¼ºï¼ˆé»˜è®¤ï¼‰"
            echo "  --no_online_augment          å…³é—­åœ¨çº¿å¢å¼ºï¼Œä½¿ç”¨é¢„ç”Ÿæˆæ•°æ®"
            echo "  --clean_train_file <path>    å¹²å‡€è®­ç»ƒå¥å­æ–‡ä»¶"
            echo "  --frozen_dev_file <path>     å›ºå®šéªŒè¯é›†æ–‡ä»¶"
            echo "  --clean_file_format <fmt>    å¹²å‡€æ–‡ä»¶æ ¼å¼ï¼ˆtxt/json/jsonlï¼‰"
            echo "  --p_corrupt <float>          é€ é”™æ¦‚ç‡ï¼ˆ0-1ï¼‰"
            echo "  --base_lambda <float>        åŸºç¡€æ³Šæ¾å‚æ•°"
            echo "  --pi_skip <float>            åˆ å­—æ¦‚ç‡"
            echo "  --pi_multiply <float>        é‡å¤å­—æ¦‚ç‡"
            echo "  --pi_replace <float>         é”™å­—æ¦‚ç‡"
            echo "  --no_length_adaptive         å…³é—­é•¿åº¦è‡ªé€‚åº”Î»"
            echo "  --min_lambda <float>         æœ€å°Î»å€¼"
            echo "  --max_lambda <float>         æœ€å¤§Î»å€¼"
            echo ""
            echo "å¤§æ•°æ®é›†å†…å­˜ä¼˜åŒ–é€‰é¡¹:"
            echo "  --lazy_load                  å¯ç”¨æƒ°æ€§åŠ è½½ï¼ˆæ¨è>100ä¸‡æ ·æœ¬æ•°æ®é›†ä½¿ç”¨ï¼‰"
            echo ""
            echo "MASK æ¨¡å¼é€‰é¡¹:"
            echo "  --full_mask_mode             Full MASK æ¨¡å¼ï¼ˆReLM é£æ ¼ï¼Œé»˜è®¤ï¼‰"
            echo "  --sparse_mask_mode           ç¨€ç– MASK æ¨¡å¼ï¼ˆåªåœ¨ç¼–è¾‘ä½ç½®æ”¾ MASKï¼‰"
            echo ""
            echo "é¢„è®¡ç®— tokenize æ•°æ®é€‰é¡¹ï¼ˆæœ€é«˜æ•ˆæ¨¡å¼ï¼‰:"
            echo "  --tokenized_data             ä½¿ç”¨é¢„è®¡ç®—çš„äºŒè¿›åˆ¶æ•°æ®"
            echo "  --train_data_prefix <path>   è®­ç»ƒæ•°æ®å‰ç¼€ï¼ˆä¸å« .bin/.idxï¼‰"
            echo "  --dev_data_prefix <path>     éªŒè¯æ•°æ®å‰ç¼€ï¼ˆä¸å« .bin/.idxï¼‰"
            echo "  --test_data_prefix <path>    æµ‹è¯•æ•°æ®å‰ç¼€ï¼ˆå¯é€‰ï¼‰"
            exit 1
            ;;
    esac
done

# ========== æ£€æŸ¥å¿…éœ€å‚æ•° ==========
if [ -z "$TRAIN_FILE" ]; then
    echo "âŒ Error: --train_file is required"
    echo ""
    echo "Usage example:"
    echo "  bash scripts/run_ddp.sh \\"
    echo "    --train_file ./data/mucgec_train.json \\"
    echo "    --dev_file ./data/mucgec_dev.json \\"
    echo "    --num_gpus 2"
    exit 1
fi

if [ ! -f "$TRAIN_FILE" ]; then
    echo "âŒ Error: Training file not found: $TRAIN_FILE"
    exit 1
fi

if [ -n "$DEV_FILE" ] && [ ! -f "$DEV_FILE" ]; then
    echo "âš ï¸ Warning: Dev file not found: $DEV_FILE"
    echo "Will skip validation during training."
    DEV_FILE=""
fi

# ========== åˆ›å»ºè¾“å‡ºç›®å½• ==========
mkdir -p "$OUTPUT_DIR"
mkdir -p "$CACHE_DIR"

# ========== æ‰“å°è®­ç»ƒé…ç½® ==========
echo ""
echo "=========================================="
echo "  Gap-ReLM DDP å¤šå¡è”åˆè®­ç»ƒ"
echo "=========================================="
echo ""
echo "ã€æ•°æ®é…ç½®ã€‘"
echo "  è®­ç»ƒæ–‡ä»¶: $TRAIN_FILE"
echo "  éªŒè¯æ–‡ä»¶: ${DEV_FILE:-None}"
echo "  æ•°æ®æ ¼å¼: $DATA_FORMAT"
echo ""
echo "ã€è®­ç»ƒé…ç½®ã€‘"
echo "  è®­ç»ƒé˜¶æ®µ: $TRAINING_STAGE"
echo "  GPUæ•°é‡:  $NUM_GPUS"
echo "  Batch Size: $BATCH_SIZE (per GPU)"
echo "  æ€»Batch: $((NUM_GPUS * BATCH_SIZE))"
echo "  è®­ç»ƒè½®æ•°: $NUM_EPOCHS"
echo "  å­¦ä¹ ç‡:   $LEARNING_RATE"
echo ""
echo "ã€æ¨¡å‹é…ç½®ã€‘"
echo "  é¢„è®­ç»ƒæ¨¡å‹: $PRETRAINED_MODEL"
echo "  æœ€å¤§åºåˆ—é•¿åº¦: $MAX_SEQ_LENGTH"
echo "  æœ€å¤§æ’å…¥æ•°: $MAX_INSERT_NUM"
echo ""
echo "ã€è¾“å‡ºé…ç½®ã€‘"
echo "  è¾“å‡ºç›®å½•: $OUTPUT_DIR"
echo "  å®éªŒåç§°: $EXPERIMENT_NAME"
echo ""
echo "ã€åŠŸèƒ½å¼€å…³ã€‘"
echo "  å¯ç”¨æ’å…¥: $ENABLE_INSERT"
echo "  å¯ç”¨åˆ é™¤: $ENABLE_DELETE"
echo "  è¾…åŠ©MLM:  $ENABLE_AUX_MLM"
echo "  P-Tuning: $ENABLE_PTUNING"
echo "  Prompté•¿åº¦: $PTUNING_PROMPT_LENGTH"
echo "  F2ä¼˜åŒ–:   $ENABLE_F2"
echo "  FP16:     $USE_FP16"
echo "  Full MASKæ¨¡å¼: $FULL_MASK_MODE"
echo ""
echo "ã€åœ¨çº¿åŠ¨æ€å¢å¼ºã€‘"
echo "  å¯ç”¨åœ¨çº¿å¢å¼º: $ONLINE_AUGMENT"
if [ "$USE_TOKENIZED_DATA" = true ]; then
    echo ""
    echo "ã€é¢„è®¡ç®— tokenize æ•°æ®ã€‘"
    echo "  è®­ç»ƒæ•°æ®å‰ç¼€: $TRAIN_DATA_PREFIX"
    echo "  éªŒè¯æ•°æ®å‰ç¼€: ${DEV_DATA_PREFIX:-None}"
    echo "  æµ‹è¯•æ•°æ®å‰ç¼€: ${TEST_DATA_PREFIX:-None}"
elif [ "$ONLINE_AUGMENT" = true ]; then
    echo "  å¹²å‡€è®­ç»ƒæ–‡ä»¶: ${CLEAN_TRAIN_FILE:-$TRAIN_FILE}"
    echo "  å›ºå®šéªŒè¯é›†:   ${FROZEN_DEV_FILE:-$DEV_FILE}"
    echo "  é€ é”™æ¦‚ç‡:     $P_CORRUPT"
    echo "  åŸºç¡€Î»:        $BASE_LAMBDA"
    echo "  é•¿åº¦è‡ªé€‚åº”:   $ENABLE_LENGTH_ADAPTIVE"
    if [ "$ENABLE_LENGTH_ADAPTIVE" = true ]; then
        echo "  Î»èŒƒå›´:        [$MIN_LAMBDA, $MAX_LAMBDA]"
    fi
fi
echo ""
echo "=========================================="
echo ""

# ========== æ„å»ºè®­ç»ƒå‘½ä»¤ ==========
CMD="torchrun \
    --nproc_per_node=$NUM_GPUS \
    --master_port=29500 \
    scripts/train.py \
    --train_file \"$TRAIN_FILE\" \
    --data_format $DATA_FORMAT \
    --output_dir \"$OUTPUT_DIR\" \
    --experiment_name \"$EXPERIMENT_NAME\" \
    --training_stage $TRAINING_STAGE \
    --pretrained_model $PRETRAINED_MODEL \
    --max_seq_length $MAX_SEQ_LENGTH \
    --max_insert_num $MAX_INSERT_NUM \
    --batch_size $BATCH_SIZE \
    --num_epochs $NUM_EPOCHS \
    --learning_rate $LEARNING_RATE \
    --warmup_ratio $WARMUP_RATIO \
    --weight_decay $WEIGHT_DECAY \
    --gradient_accumulation_steps $GRADIENT_ACCUMULATION_STEPS \
    --num_workers $NUM_WORKERS \
    --prefetch_factor $PREFETCH_FACTOR \
    --cache_dir \"$CACHE_DIR\" \
    --logging_steps $LOGGING_STEPS \
    --save_steps $SAVE_STEPS \
    --eval_steps $EVAL_STEPS \
    --seed $SEED"

# æ·»åŠ å¯é€‰å‚æ•°
if [ -n "$DEV_FILE" ]; then
    CMD="$CMD --dev_file \"$DEV_FILE\""
fi

if [ "$USE_CACHE" = true ]; then
    CMD="$CMD"  # é»˜è®¤å¯ç”¨ç¼“å­˜
else
    CMD="$CMD --no_cache"
fi

if [ "$USE_FP16" = true ]; then
    CMD="$CMD --fp16"
fi

if [ "$USE_BF16" = true ]; then
    CMD="$CMD --bf16"
fi

if [ "$ENABLE_INSERT" = false ]; then
    CMD="$CMD --no_insert"
fi

if [ "$ENABLE_DELETE" = false ]; then
    CMD="$CMD --no_delete"
fi

if [ "$ENABLE_AUX_MLM" = false ]; then
    CMD="$CMD --no_aux_mlm"
fi

if [ "$ENABLE_F2" = false ]; then
    CMD="$CMD --no_f2"
fi

# P-Tuning é…ç½®
if [ "$ENABLE_PTUNING" = false ]; then
    CMD="$CMD --no_ptuning"
fi

if [ "$PTUNING_USE_LSTM" = false ]; then
    CMD="$CMD --ptuning_no_lstm"
fi

if [ "$PTUNING_SHARED" = true ]; then
    CMD="$CMD --ptuning_shared"
fi

CMD="$CMD --ptuning_prompt_length $PTUNING_PROMPT_LENGTH"

# MASK æ¨¡å¼é…ç½®
if [ "$FULL_MASK_MODE" = true ]; then
    CMD="$CMD --full_mask_mode"
else
    CMD="$CMD --sparse_mask_mode"
fi

# é¢„è®¡ç®— tokenize æ•°æ®é…ç½®ï¼ˆæœ€é«˜æ•ˆæ¨¡å¼ï¼‰
if [ "$USE_TOKENIZED_DATA" = true ]; then
    CMD="$CMD --tokenized_data"

    if [ -n "$TRAIN_DATA_PREFIX" ]; then
        CMD="$CMD --train_data_prefix \"$TRAIN_DATA_PREFIX\""
    else
        echo "âŒ Error: --train_data_prefix is required when using --tokenized_data"
        exit 1
    fi

    if [ -n "$DEV_DATA_PREFIX" ]; then
        CMD="$CMD --dev_data_prefix \"$DEV_DATA_PREFIX\""
    fi

    if [ -n "$TEST_DATA_PREFIX" ]; then
        CMD="$CMD --test_data_prefix \"$TEST_DATA_PREFIX\""
    fi
# åœ¨çº¿åŠ¨æ€æ•°æ®å¢å¼ºé…ç½®
elif [ "$ONLINE_AUGMENT" = true ]; then
    CMD="$CMD --online_augment"

    # å¹²å‡€è®­ç»ƒæ–‡ä»¶ï¼ˆå¦‚æœæŒ‡å®šï¼‰
    if [ -n "$CLEAN_TRAIN_FILE" ]; then
        CMD="$CMD --clean_train_file \"$CLEAN_TRAIN_FILE\""
    fi

    # å›ºå®šéªŒè¯é›†ï¼ˆå¦‚æœæŒ‡å®šï¼‰
    if [ -n "$FROZEN_DEV_FILE" ]; then
        CMD="$CMD --frozen_dev_file \"$FROZEN_DEV_FILE\""
    fi

    # é€ é”™å‚æ•°
    CMD="$CMD --p_corrupt $P_CORRUPT"
    CMD="$CMD --base_lambda $BASE_LAMBDA"
    CMD="$CMD --pi_skip $PI_SKIP"
    CMD="$CMD --pi_multiply $PI_MULTIPLY"
    CMD="$CMD --pi_replace $PI_REPLACE"
    CMD="$CMD --clean_file_format $CLEAN_FILE_FORMAT"

    # é•¿åº¦è‡ªé€‚åº”é…ç½®
    if [ "$ENABLE_LENGTH_ADAPTIVE" = true ]; then
        CMD="$CMD --enable_length_adaptive"
        CMD="$CMD --min_lambda $MIN_LAMBDA"
        CMD="$CMD --max_lambda $MAX_LAMBDA"
        CMD="$CMD --min_length_for_lambda $MIN_LENGTH_FOR_LAMBDA"
        CMD="$CMD --max_length_for_lambda $MAX_LENGTH_FOR_LAMBDA"
    else
        CMD="$CMD --no_length_adaptive"
    fi
# é™æ€æ•°æ®æ¨¡å¼ï¼ˆä¸ä½¿ç”¨é¢„è®¡ç®— tokenizeï¼Œä¹Ÿä¸ä½¿ç”¨åœ¨çº¿å¢å¼ºï¼‰
else
    CMD="$CMD --no_online_augment"

    # æƒ°æ€§åŠ è½½ï¼ˆä»…åœ¨é™æ€ JSONL æ•°æ®æ¨¡å¼ä¸‹ç”Ÿæ•ˆï¼‰
    if [ "$LAZY_LOAD" = true ]; then
        CMD="$CMD --lazy_load"
    fi
fi

# ========== è¿è¡Œè®­ç»ƒ ==========
echo "ğŸš€ Starting training..."
echo ""

eval $CMD

# ========== è®­ç»ƒå®Œæˆ ==========
if [ $? -eq 0 ]; then
    echo ""
    echo "=========================================="
    echo "  âœ… Training completed successfully!"
    echo "=========================================="
    echo ""
    echo "ã€è¾“å‡ºç›®å½•ã€‘"
    echo "  æ¨¡å‹æ£€æŸ¥ç‚¹: $OUTPUT_DIR/"
    echo "  TensorBoard: tensorboard --logdir=$OUTPUT_DIR/tensorboard"
    echo ""
else
    echo ""
    echo "=========================================="
    echo "  âŒ Training failed!"
    echo "=========================================="
    exit 1
fi
